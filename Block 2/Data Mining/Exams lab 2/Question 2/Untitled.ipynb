{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import wget\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import load_model\n",
    "import io\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import io\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina' \n",
    "\n",
    "def load_image_from_url(url, target_size=None, color_mode='rgb'):\n",
    "    assert color_mode in ('grayscale', 'rgb'), 'color_mode must be \"grayscale\" or \"rgb\"'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    img = Image.open(io.BytesIO(response.read()))\n",
    "    img = img.convert('RGB')\n",
    "    if color_mode == 'grayscale':\n",
    "        img = ImageOps.grayscale(img)\n",
    "    if target_size:\n",
    "        img = img.resize(target_size, Image.NEAREST) # resize\n",
    "    return image.img_to_array(img)\n",
    "\n",
    "def load_image_from_path(image_path, target_size=None, color_mode='rgb'):\n",
    "    pil_image = image.load_img(image_path, \n",
    "                               target_size=target_size,\n",
    "                            color_mode=color_mode)\n",
    "    return image.img_to_array(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path\n",
       "0  C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...\n",
       "1  C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...\n",
       "2  C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...\n",
       "3  C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat...\n",
       "4  C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Dat..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for image in os.listdir(r'C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Data Mining\\Exams lab 2\\Question 2\\CEO\\\\'): # Loop through the folder\n",
    "    file_name = os.fsdecode(image)\n",
    "    file_name = r'C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Data Mining\\Exams lab 2\\Question 2\\CEO\\\\' + file_name # Copy the folder name & image name\n",
    "    paths.append(file_name)\n",
    "df = pd.DataFrame(paths, columns=[\"Path\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len ( df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b1afecbc0a49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mOur_Image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Data Mining\\Exams lab 2\\Question 2\\CEO\\9.ceo.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcolor_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOur_Image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8b89bb59c0ba>\u001b[0m in \u001b[0;36mload_image_from_path\u001b[1;34m(image_path, target_size, color_mode)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_image_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     pil_image = image.load_img(image_path, \n\u001b[0m\u001b[0;32m     16\u001b[0m                                \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                             color_mode=color_mode)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "Our_Image = r'C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Data Mining\\Exams lab 2\\Question 2\\CEO\\9.ceo.jpg'\n",
    "color_image = load_image_from_path(Our_Image)\n",
    "\n",
    "plt.imshow(color_image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a list of all movie poster file names.\n",
    "mypath = r'C:\\Users\\pc\\Desktop\\MASTER COURSES\\Block 2\\Data Mining\\Exams lab 2\\Question 2\\CEO'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posters = pd.DataFrame()\n",
    "posters['File_name'] = onlyfiles\n",
    "posters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "face_model = wget.download(model_url)\n",
    "\n",
    "face_classification = cv2.CascadeClassifier(model_url) # load the classifier only once!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_offsets(face_coordinates, offsets):\n",
    "    \"\"\"\n",
    "    Derived from https://github.com/oarriaga/face_classification/blob/\n",
    "    b861d21b0e76ca5514cdeb5b56a689b7318584f4/src/utils/inference.py#L21\n",
    "    \"\"\"\n",
    "    x, y, width, height = face_coordinates\n",
    "    x_off, y_off = offsets\n",
    "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
    "\n",
    "gender_classifier = load_model('gender_mini_XCEPTION.21-0.95.hdf5') # load this only once! (not in a loop)\n",
    "GENDER_OFFSETS = (10, 10)\n",
    "INPUT_SHAPE_GENDER = gender_classifier.input_shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_image = load_image_from_path(r'C:\\\\Users\\\\pc\\\\Desktop\\\\MASTER COURSES\\\\Block 2\\\\Data Mining\\\\Exams lab 2\\\\Question 2\\\\CEO\\\\\\\\10.getty_640189368_393093.jpg',\n",
    "                        color_mode='rgb') # \n",
    "plt.imshow(color_image.astype(np.uint8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faces_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(df))):\n",
    "    pre_image = load_image_from_path(df.Path.values[i], color_mode='grayscale')\n",
    "    gray_image = np.squeeze(pre_image).astype('uint8')\n",
    "\n",
    "    face_classification = cv2.CascadeClassifier(face_model) # load the classifier \n",
    "    faces = face_classification.detectMultiScale(gray_image, 1.3, 5) # detect the faces \n",
    "    n_faces = len(faces) # get the number of faces\n",
    "    n_faces_list.append(n_faces)\n",
    "\n",
    "posters['n_faces'] = n_faces_list\n",
    "posters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Path.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors\n",
    "\n",
    "def get_colour_name(rgb_triplet):\n",
    "    \"\"\"\n",
    "    From https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green-with-python\n",
    "    \"\"\"\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.CSS21_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb_triplet[0]) ** 2\n",
    "        gd = (g_c - rgb_triplet[1]) ** 2\n",
    "        bd = (b_c - rgb_triplet[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "colors_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(df))):\n",
    "    color_image = load_image_from_path(df.Path.values[i],color_mode='rgb')\n",
    "    img = Image.fromarray(color_image.astype(np.uint8)) # convert to PIL image object\n",
    "    colors = colorgram.extract(img, 1) \n",
    "\n",
    "    for color in colors:\n",
    "        rgb = tuple(color.rgb)\n",
    "        color_name = get_colour_name(rgb)\n",
    "    \n",
    "    colors_list.append(color_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Landscape['Dominant_color'] = colors_list\n",
    "Landscape.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
