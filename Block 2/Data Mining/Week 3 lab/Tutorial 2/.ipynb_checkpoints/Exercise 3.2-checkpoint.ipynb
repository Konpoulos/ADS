{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Load the data using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pickle.load(open('gender.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finally, some women journalists mentioned that information and communication technologies are responsible for creating new barriers for women in journalism because of the increased pace and pressure on their private lives.',\n",
       " 'Still, it is necessary to first establish that language itself might play a bias-inducing role before assessing whether such bias can be overcome via another mechanism.',\n",
       " 'The process of constructing a national identity directly engages the construction of gender (Charrad 2001; Kandiyoti 1991; Kim, Puri, and Kim-Puri 2005; Yuval-Davis and Anthias 1989), and Sudan is no exception (Hale 1996; Nageeb 2004; Tønnessen 2007).',\n",
       " 'What is the point of all this that these people do [pointing at his colleagues in the shop]—knives and women and who knows what else?',\n",
       " 'The first part of this article will question whether restorative justice mechanisms can be more conducive to the inclusion of women’s experiences.',\n",
       " 'If the Thug stereotypes the public lives of Black men, the Deadbeat Dad is tied to the private sphere.',\n",
       " 'However, Resolution 2106 clearly concentrates on women and girls as ‘disproportionately’ affected by sexual violence, with men and boys as secondary victims.',\n",
       " 'In particular, our findings hint that gender may become more meaningful when workers have a shorter work history with an organization; this deserves further exploration.',\n",
       " 'In the same way, abortions must be banned.',\n",
       " 'Figure 3.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Tokenize the lowercased texts using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, '')\n",
    "    text = text.lower() \n",
    "    text = text.split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['finally', 'some', 'women', 'journalists', 'mentioned', 'that', 'information', 'and', 'communication', 'technologies', 'are', 'responsible', 'for', 'creating', 'new', 'barriers', 'for', 'women', 'in', 'journalism', 'because', 'of', 'the', 'increased', 'pace', 'and', 'pressure', 'on', 'their', 'private', 'lives'], ['still', 'it', 'is', 'necessary', 'to', 'first', 'establish', 'that', 'language', 'itself', 'might', 'play', 'a', 'biasinducing', 'role', 'before', 'assessing', 'whether', 'such', 'bias', 'can', 'be', 'overcome', 'via', 'another', 'mechanism'], ['the', 'process', 'of', 'constructing', 'a', 'national', 'identity', 'directly', 'engages', 'the', 'construction', 'of', 'gender', 'charrad', '2001', 'kandiyoti', '1991', 'kim', 'puri', 'and', 'kimpuri', '2005', 'yuvaldavis', 'and', 'anthias', '1989', 'and', 'sudan', 'is', 'no', 'exception', 'hale', '1996', 'nageeb', '2004', 'tønnessen', '2007'], ['what', 'is', 'the', 'point', 'of', 'all', 'this', 'that', 'these', 'people', 'do', 'pointing', 'at', 'his', 'colleagues', 'in', 'the', 'shop—knives', 'and', 'women', 'and', 'who', 'knows', 'what', 'else'], ['the', 'first', 'part', 'of', 'this', 'article', 'will', 'question', 'whether', 'restorative', 'justice', 'mechanisms', 'can', 'be', 'more', 'conducive', 'to', 'the', 'inclusion', 'of', 'women’s', 'experiences'], ['if', 'the', 'thug', 'stereotypes', 'the', 'public', 'lives', 'of', 'black', 'men', 'the', 'deadbeat', 'dad', 'is', 'tied', 'to', 'the', 'private', 'sphere'], ['however', 'resolution', '2106', 'clearly', 'concentrates', 'on', 'women', 'and', 'girls', 'as', '‘disproportionately’', 'affected', 'by', 'sexual', 'violence', 'with', 'men', 'and', 'boys', 'as', 'secondary', 'victims'], ['in', 'particular', 'our', 'findings', 'hint', 'that', 'gender', 'may', 'become', 'more', 'meaningful', 'when', 'workers', 'have', 'a', 'shorter', 'work', 'history', 'with', 'an', 'organization', 'this', 'deserves', 'further', 'exploration'], ['in', 'the', 'same', 'way', 'abortions', 'must', 'be', 'banned'], ['figure', '3']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [tokenize(text) for text in text]\n",
    "print(tokenized_texts[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we tokenize it we are ready to train our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7724048, 10383330)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = 300 # dimensions of the embeddings\n",
    "SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "WINDOW = 10 # the window size\n",
    "N_WORKERS = 1 # number of workers to use\n",
    "MIN_COUNT = 5\n",
    "\n",
    "model = Word2Vec(size=SIZE,\n",
    "                sg=SG,\n",
    "                window=WINDOW, \n",
    "                min_count=MIN_COUNT,\n",
    "                workers=N_WORKERS)\n",
    "\n",
    "model.build_vocab(tokenized_texts)\n",
    "\n",
    "model.train(tokenized_texts,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=model.epochs) # grab some coffee while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\") # if we want to save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\") # if we want to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(model.wv['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Use the most_similar() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('macrolevel', 0.6259261965751648),\n",
       " ('cityliving', 0.602796196937561),\n",
       " ('religion’s', 0.5937982201576233),\n",
       " ('underexamined', 0.5903353095054626),\n",
       " ('disaggregated', 0.5810270309448242),\n",
       " ('realworld', 0.5732666850090027),\n",
       " ('gender”', 0.5696383714675903),\n",
       " ('inequity', 0.5683953762054443),\n",
       " ('genderbiased', 0.5662651658058167),\n",
       " ('nascent', 0.560550332069397)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get some words that we expect like genderbiased but most of the words doesn't make much sence to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Calculate the similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42740187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('man', 'king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25433987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('woman', 'king'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the man king has better score because they  are more similar to woman king instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  Part 2: Reproducing Wevers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = pickle.load(open('word_cats.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>percept</th>\n",
       "      <th>body</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protesting</td>\n",
       "      <td>incentive</td>\n",
       "      <td>destruction</td>\n",
       "      <td>chick</td>\n",
       "      <td>ma's</td>\n",
       "      <td>comply</td>\n",
       "      <td>squeez</td>\n",
       "      <td>pussy</td>\n",
       "      <td>dotcom</td>\n",
       "      <td>dnd</td>\n",
       "      <td>portfolio</td>\n",
       "      <td>goddess</td>\n",
       "      <td>accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty</td>\n",
       "      <td>luck</td>\n",
       "      <td>beaten</td>\n",
       "      <td>ma's</td>\n",
       "      <td>niece</td>\n",
       "      <td>luck</td>\n",
       "      <td>sand</td>\n",
       "      <td>wears</td>\n",
       "      <td>employee</td>\n",
       "      <td>vacation</td>\n",
       "      <td>sale</td>\n",
       "      <td>karma</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sighs</td>\n",
       "      <td>freeing</td>\n",
       "      <td>battl</td>\n",
       "      <td>lets</td>\n",
       "      <td>stepkid</td>\n",
       "      <td>unquestion</td>\n",
       "      <td>moist</td>\n",
       "      <td>hearts</td>\n",
       "      <td>paper</td>\n",
       "      <td>hobb</td>\n",
       "      <td>stores</td>\n",
       "      <td>pastor</td>\n",
       "      <td>actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>warmth</td>\n",
       "      <td>pretty</td>\n",
       "      <td>protesting</td>\n",
       "      <td>son's</td>\n",
       "      <td>son's</td>\n",
       "      <td>pretty</td>\n",
       "      <td>warmth</td>\n",
       "      <td>asleep</td>\n",
       "      <td>earns</td>\n",
       "      <td>band</td>\n",
       "      <td>bets</td>\n",
       "      <td>temple</td>\n",
       "      <td>actuary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooch</td>\n",
       "      <td>nicely</td>\n",
       "      <td>dumber</td>\n",
       "      <td>daddies</td>\n",
       "      <td>daddies</td>\n",
       "      <td>become</td>\n",
       "      <td>gloomy</td>\n",
       "      <td>gums</td>\n",
       "      <td>assign</td>\n",
       "      <td>skat</td>\n",
       "      <td>bank</td>\n",
       "      <td>holy</td>\n",
       "      <td>acupuncturist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>easily</td>\n",
       "      <td>well</td>\n",
       "      <td>mock</td>\n",
       "      <td>mock</td>\n",
       "      <td>step-dau</td>\n",
       "      <td>complication</td>\n",
       "      <td>watching</td>\n",
       "      <td>stomach</td>\n",
       "      <td>benefits</td>\n",
       "      <td>artsy</td>\n",
       "      <td>rupee</td>\n",
       "      <td>religio</td>\n",
       "      <td>adjustor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trust</td>\n",
       "      <td>benefits</td>\n",
       "      <td>offenses</td>\n",
       "      <td>bachelorette</td>\n",
       "      <td>widow</td>\n",
       "      <td>lot</td>\n",
       "      <td>oil</td>\n",
       "      <td>spit</td>\n",
       "      <td>taxa</td>\n",
       "      <td>spotify</td>\n",
       "      <td>fortune</td>\n",
       "      <td>shiite</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>delicate</td>\n",
       "      <td>agreeableness</td>\n",
       "      <td>unimportant</td>\n",
       "      <td>fought</td>\n",
       "      <td>papa</td>\n",
       "      <td>discover</td>\n",
       "      <td>stroki</td>\n",
       "      <td>wearing</td>\n",
       "      <td>auditorium</td>\n",
       "      <td>margarita</td>\n",
       "      <td>dimes</td>\n",
       "      <td>rosary</td>\n",
       "      <td>agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pitiable</td>\n",
       "      <td>admir</td>\n",
       "      <td>weakened</td>\n",
       "      <td>lassie</td>\n",
       "      <td>godparent</td>\n",
       "      <td>randomly</td>\n",
       "      <td>gripp</td>\n",
       "      <td>horny</td>\n",
       "      <td>consult</td>\n",
       "      <td>bowling</td>\n",
       "      <td>taxa</td>\n",
       "      <td>allah</td>\n",
       "      <td>airman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>heroism</td>\n",
       "      <td>neat</td>\n",
       "      <td>fought</td>\n",
       "      <td>acquainta</td>\n",
       "      <td>grandm</td>\n",
       "      <td>wonders</td>\n",
       "      <td>grey</td>\n",
       "      <td>wore</td>\n",
       "      <td>photocop</td>\n",
       "      <td>ep</td>\n",
       "      <td>chequ</td>\n",
       "      <td>sikh</td>\n",
       "      <td>almoner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       affect         posemo       negemo        social     family  \\\n",
       "0  protesting      incentive  destruction         chick       ma's   \n",
       "1      pretty           luck       beaten          ma's      niece   \n",
       "2       sighs        freeing        battl          lets    stepkid   \n",
       "3      warmth         pretty   protesting         son's      son's   \n",
       "4       mooch         nicely       dumber       daddies    daddies   \n",
       "5      easily           well         mock          mock   step-dau   \n",
       "6       trust       benefits     offenses  bachelorette      widow   \n",
       "7    delicate  agreeableness  unimportant        fought       papa   \n",
       "8    pitiable          admir     weakened        lassie  godparent   \n",
       "9     heroism           neat       fought     acquainta     grandm   \n",
       "\n",
       "        cogproc   percept     body        work    leisure      money    relig  \\\n",
       "0        comply    squeez    pussy      dotcom        dnd  portfolio  goddess   \n",
       "1          luck      sand    wears    employee   vacation       sale    karma   \n",
       "2    unquestion     moist   hearts       paper       hobb     stores   pastor   \n",
       "3        pretty    warmth   asleep       earns       band       bets   temple   \n",
       "4        become    gloomy     gums      assign       skat       bank     holy   \n",
       "5  complication  watching  stomach    benefits      artsy      rupee  religio   \n",
       "6           lot       oil     spit        taxa    spotify    fortune   shiite   \n",
       "7      discover    stroki  wearing  auditorium  margarita      dimes   rosary   \n",
       "8      randomly     gripp    horny     consult    bowling       taxa    allah   \n",
       "9       wonders      grey     wore    photocop         ep      chequ     sikh   \n",
       "\n",
       "      occupation  \n",
       "0     accountant  \n",
       "1          actor  \n",
       "2        actress  \n",
       "3        actuary  \n",
       "4  acupuncturist  \n",
       "5       adjustor  \n",
       "6  administrator  \n",
       "7          agent  \n",
       "8         airman  \n",
       "9        almoner  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the words are combined as in Dutch then we miss some words if we are using an English text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean embedding of male related words: (300,)\n"
     ]
    }
   ],
   "source": [
    "male_words = ['he', 'his', 'him', 'male', 'man', 'boy', 'son', 'father', 'dad', 'brother','car','ball','drinks']\n",
    "words = [word for word in male_words if word in model.wv.vocab]\n",
    "mean_embedding = np.mean([model.wv[word] for word in words], axis=0)\n",
    "print(f'Mean embedding of male related words: {mean_embedding.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean embedding of female related words: (300,)\n"
     ]
    }
   ],
   "source": [
    "female_words = ['she', 'her', 'her', 'female', 'woman', 'girl', 'daughter', 'mother', 'mom', 'sister','kids','nails']\n",
    "words = [word for word in female_words if word in model.wv.vocab]\n",
    "mean_embedding = np.mean([model.wv[word] for word in words], axis=0)\n",
    "print(f'Mean embedding of female related words: {mean_embedding.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.To get an indication of the gender bias related to a certain category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
