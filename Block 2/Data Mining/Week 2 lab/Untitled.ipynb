{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"labeled_tweets.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @WaysMeansCmte: Republican Senators need to...</td>\n",
       "      <td>Laid-off workers set up soup kitchens in front...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff Van Drew sold out his district and his co...</td>\n",
       "      <td>Pitch in to help Amy Kennedy defeat Jeff Van D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker Pelosi has failed the American people‚Äî...</td>\n",
       "      <td>House Minority Leader McCarthy: Pelosi touts D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To learn more about global efforts to #EndPoli...</td>\n",
       "      <td>Home | End Polio. With your help, we can end p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @realDailyWire: BREAKING: Hunter Biden Rece...</td>\n",
       "      <td>Hunter Biden Received Millions From Wife Of Ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0  RT @WaysMeansCmte: Republican Senators need to...   \n",
       "1  Jeff Van Drew sold out his district and his co...   \n",
       "2  Speaker Pelosi has failed the American people‚Äî...   \n",
       "3  To learn more about global efforts to #EndPoli...   \n",
       "4  RT @realDailyWire: BREAKING: Hunter Biden Rece...   \n",
       "\n",
       "                                              text_b  label  \n",
       "0  Laid-off workers set up soup kitchens in front...      2  \n",
       "1  Pitch in to help Amy Kennedy defeat Jeff Van D...      0  \n",
       "2  House Minority Leader McCarthy: Pelosi touts D...      1  \n",
       "3  Home | End Polio. With your help, we can end p...      1  \n",
       "4  Hunter Biden Received Millions From Wife Of Ex...      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1377\n",
      "0    1275\n",
      "2     230\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0 = affirmative, 1 = negotiated, 2 =oppositional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in our dataset there are 1377 valued negotiated 1275 valued affirmative and 230 valued oppositional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1    Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.Train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will pick our train and test set in 80:20 proportion\n",
    "X = list(data.text_a.values)\n",
    "y = list(data.label.values)# the labels we want to predict --> Y\n",
    "labels = ['affirmative', 'negotiated','oppositional']\n",
    "\n",
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then we make a vocabulary of the corpus\n",
    "cv = CountVectorizer() # this initializes the CountVectorizer \n",
    "\n",
    "cv.fit(X_train_str) # create the vocabulary (using only train set!! beacause we dont want to use the test set my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now create our arrays\n",
    "X_train = cv.transform(X_train_str)\n",
    "X_test = cv.transform(X_test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.toarray()[0]) #if we want to visualize the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>01dju1d7qc</th>\n",
       "      <th>02</th>\n",
       "      <th>030dnk8aky</th>\n",
       "      <th>040tozx3x9</th>\n",
       "      <th>04knsnijuq</th>\n",
       "      <th>04mohpm9q0</th>\n",
       "      <th>05</th>\n",
       "      <th>05dagzqjuq</th>\n",
       "      <th>06nrbvul11</th>\n",
       "      <th>...</th>\n",
       "      <th>zxqv1atnft</th>\n",
       "      <th>zxxsznkil9</th>\n",
       "      <th>zyafklfryj</th>\n",
       "      <th>zyahjnplbe</th>\n",
       "      <th>zzjwvjrdtd</th>\n",
       "      <th>zzkhhjk8yh</th>\n",
       "      <th>zzm2owgnv3</th>\n",
       "      <th>√°√±ez</th>\n",
       "      <th>√ºber</th>\n",
       "      <th>ùì∏ùìæùìª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 13406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  01dju1d7qc  02  030dnk8aky  040tozx3x9  04knsnijuq  04mohpm9q0  05  \\\n",
       "0    0           0   0           0           0           0           0   0   \n",
       "1    0           0   0           0           0           0           0   0   \n",
       "2    0           0   0           0           0           0           0   0   \n",
       "3    0           0   0           0           0           0           0   0   \n",
       "4    0           0   0           0           0           0           0   0   \n",
       "\n",
       "   05dagzqjuq  06nrbvul11  ...  zxqv1atnft  zxxsznkil9  zyafklfryj  \\\n",
       "0           0           0  ...           0           0           0   \n",
       "1           0           0  ...           0           0           0   \n",
       "2           0           0  ...           0           0           0   \n",
       "3           0           0  ...           0           0           0   \n",
       "4           0           0  ...           0           0           0   \n",
       "\n",
       "   zyahjnplbe  zzjwvjrdtd  zzkhhjk8yh  zzm2owgnv3  √°√±ez  √ºber  ùì∏ùìæùìª  \n",
       "0           0           0           0           0     0     0    0  \n",
       "1           0           0           0           0     0     0    0  \n",
       "2           0           0           0           0     0     0    0  \n",
       "3           0           0           0           0     0     0    0  \n",
       "4           0           0           0           0     0     0    0  \n",
       "\n",
       "[5 rows x 13406 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we want the results of the CountVectorizer\n",
    "vocabulary = cv.get_feature_names()\n",
    "vectorized_texts = pd.DataFrame(X_train.toarray(), columns=vocabulary)\n",
    "vectorized_texts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will train our model \n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " affirmative       0.57      0.62      0.60       256\n",
      "  negotiated       0.55      0.59      0.57       270\n",
      "oppositional       0.20      0.04      0.07        51\n",
      "\n",
      "    accuracy                           0.55       577\n",
      "   macro avg       0.44      0.42      0.41       577\n",
      "weighted avg       0.53      0.55      0.54       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now we evaluate the performance \n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model: we see that we have almost 0.6 f1-score which is the mean of precision and recall for affirmative and negotiated but only 0.07 f1-score for oppositional which is far from good score\n",
    "Lets try the random relecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " affirmative       0.43      0.32      0.36       256\n",
      "  negotiated       0.45      0.33      0.38       270\n",
      "oppositional       0.11      0.41      0.17        51\n",
      "\n",
      "    accuracy                           0.33       577\n",
      "   macro avg       0.33      0.35      0.30       577\n",
      "weighted avg       0.41      0.33      0.35       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random selecting\n",
    "random_preds = [random.randint(0,2) for i in range(len(y_test))]\n",
    "\n",
    "print(classification_report(y_test, random_preds, \n",
    "                          target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have better f1-score for oppositional but worse score for the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.Try to interpret the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>0.738232</td>\n",
       "      <td>helping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>0.713591</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>0.704428</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>0.635511</td>\n",
       "      <td>cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>0.607617</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>0.595824</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>0.590113</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11553</th>\n",
       "      <td>0.585049</td>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>0.581932</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>0.578063</td>\n",
       "      <td>confirmation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef          word\n",
       "5583   0.738232       helping\n",
       "10305  0.713591            rt\n",
       "2839   0.704428      complete\n",
       "3189   0.635511          cruz\n",
       "1820   0.607617         below\n",
       "6493   0.595824           job\n",
       "5114   0.590113    generation\n",
       "11553  0.585049          team\n",
       "7098   0.581932          live\n",
       "2887   0.578063  confirmation"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = cv.get_feature_names()\n",
    "regression_coefficients = lr.coef_[0] # get the LR weights we have 3 types so 0 is the affirmative\n",
    "vocab_coef_combined = list(zip(regression_coefficients, vocabulary)) # this combines two separate lists [1, 2], ['word1', 'word2'] into one list [[1, 'word1'], [2, 'word2']]\n",
    "\n",
    "feature_importance = pd.DataFrame(vocab_coef_combined,\n",
    "                      columns=['coef', 'word'])\n",
    "feature_importance.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the word helping has the highest weight for affirmative titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>0.719113</td>\n",
       "      <td>guard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>0.665114</td>\n",
       "      <td>passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>0.613779</td>\n",
       "      <td>remains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12778</th>\n",
       "      <td>0.596099</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11886</th>\n",
       "      <td>0.588975</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>0.582243</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>0.578441</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>0.577510</td>\n",
       "      <td>partisan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>0.554794</td>\n",
       "      <td>means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>0.552816</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef      word\n",
       "5371   0.719113     guard\n",
       "8720   0.665114   passing\n",
       "9791   0.613779   remains\n",
       "12778  0.596099      were\n",
       "11886  0.588975     trade\n",
       "9072   0.582243      post\n",
       "2049   0.578441       box\n",
       "8701   0.577510  partisan\n",
       "7474   0.554794     means\n",
       "8969   0.552816    please"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = cv.get_feature_names()\n",
    "regression_coefficients = lr.coef_[1] # get the LR weights we have 3 types so 0 is the affirmative\n",
    "vocab_coef_combined = list(zip(regression_coefficients, vocabulary)) # this combines two separate lists [1, 2], ['word1', 'word2'] into one list [[1, 'word1'], [2, 'word2']]\n",
    "\n",
    "feature_importance = pd.DataFrame(vocab_coef_combined,\n",
    "                      columns=['coef', 'word'])\n",
    "feature_importance.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the word guard has the highest weight for negotiated titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>0.606004</td>\n",
       "      <td>around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>0.604694</td>\n",
       "      <td>heroes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>0.594951</td>\n",
       "      <td>chairman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12149</th>\n",
       "      <td>0.585844</td>\n",
       "      <td>unacceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>0.573029</td>\n",
       "      <td>fvmwrb09nu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0.573029</td>\n",
       "      <td>repdonbeyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>0.573029</td>\n",
       "      <td>mypuntxhcr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.554722</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>0.544191</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>0.541234</td>\n",
       "      <td>issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef          word\n",
       "1445   0.606004        around\n",
       "5598   0.604694        heroes\n",
       "2475   0.594951      chairman\n",
       "12149  0.585844  unacceptable\n",
       "5020   0.573029    fvmwrb09nu\n",
       "9862   0.573029   repdonbeyer\n",
       "7906   0.573029    mypuntxhcr\n",
       "1673   0.554722           bad\n",
       "8198   0.544191           not\n",
       "6325   0.541234        issues"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = cv.get_feature_names()\n",
    "regression_coefficients = lr.coef_[2] # get the LR weights we have 3 types so 0 is the affirmative\n",
    "vocab_coef_combined = list(zip(regression_coefficients, vocabulary)) # this combines two separate lists [1, 2], ['word1', 'word2'] into one list [[1, 'word1'], [2, 'word2']]\n",
    "\n",
    "feature_importance = pd.DataFrame(vocab_coef_combined,\n",
    "                      columns=['coef', 'word'])\n",
    "feature_importance.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the word around has the highest weight for oppositional titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.Use TF-IDF features instead of raw counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer() \n",
    "\n",
    "tfidf.fit(X_train_str) # create the vocabulary\n",
    "\n",
    "X_train_idf = tfidf.transform(X_train_str)\n",
    "X_test = tfidf.transform(X_test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',max_iter = 1000)\n",
    "lr.fit(X_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " affirmative       0.64      0.56      0.60       256\n",
      "  negotiated       0.55      0.72      0.62       270\n",
      "oppositional       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.59       577\n",
      "   macro avg       0.40      0.43      0.41       577\n",
      "weighted avg       0.54      0.59      0.56       577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 BERT: supervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
