{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import tensorflow_hub as hub\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import colorgram\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "import matplotlib as mpl\n",
    "import webcolors\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import wget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url, target_size=None, color_mode='rgb'):\n",
    "    assert color_mode in ('grayscale', 'rgb'), 'color_mode must be \"grayscale\" or \"rgb\"'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    img = Image.open(io.BytesIO(response.read()))\n",
    "    img = img.convert('RGB')\n",
    "    if color_mode == 'grayscale':\n",
    "        img = ImageOps.grayscale(img)\n",
    "    if target_size:\n",
    "        img = img.resize(target_size, Image.NEAREST) # resize\n",
    "    return image.img_to_array(img)\n",
    "\n",
    "def load_image_from_path(image_path, target_size=None, color_mode='rgb'):\n",
    "    pil_image = image.load_img(image_path, \n",
    "                               target_size=target_size,\n",
    "                            color_mode=color_mode)\n",
    "    return image.img_to_array(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a list of all movie poster file names.\n",
    "mypath = 'movie_posters/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 7: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 7: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0157f103436c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import the csv file with data from IMDB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MovieGenre.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2157\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2158\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 7: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# import the csv file with data from IMDB\n",
    "imdb = pd.read_csv('MovieGenre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Imdb Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Score</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.imdb.com/title/tt114709</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>113497</td>\n",
       "      <td>http://www.imdb.com/title/tt113497</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>113228</td>\n",
       "      <td>http://www.imdb.com/title/tt113228</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>114885</td>\n",
       "      <td>http://www.imdb.com/title/tt114885</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>113041</td>\n",
       "      <td>http://www.imdb.com/title/tt113041</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId                           Imdb Link  \\\n",
       "0  114709  http://www.imdb.com/title/tt114709   \n",
       "1  113497  http://www.imdb.com/title/tt113497   \n",
       "2  113228  http://www.imdb.com/title/tt113228   \n",
       "3  114885  http://www.imdb.com/title/tt114885   \n",
       "4  113041  http://www.imdb.com/title/tt113041   \n",
       "\n",
       "                                Title  IMDB Score                       Genre  \\\n",
       "0                    Toy Story (1995)         8.3  Animation|Adventure|Comedy   \n",
       "1                      Jumanji (1995)         6.9     Action|Adventure|Family   \n",
       "2             Grumpier Old Men (1995)         6.6              Comedy|Romance   \n",
       "3            Waiting to Exhale (1995)         5.7        Comedy|Drama|Romance   \n",
       "4  Father of the Bride Part II (1995)         5.9       Comedy|Family|Romance   \n",
       "\n",
       "                                              Poster  \n",
       "0  https://images-na.ssl-images-amazon.com/images...  \n",
       "1  https://images-na.ssl-images-amazon.com/images...  \n",
       "2  https://images-na.ssl-images-amazon.com/images...  \n",
       "3  https://images-na.ssl-images-amazon.com/images...  \n",
       "4  https://images-na.ssl-images-amazon.com/images...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40108 entries, 0 to 40107\n",
      "Data columns (total 6 columns):\n",
      "imdbId        40108 non-null int64\n",
      "Imdb Link     40108 non-null object\n",
      "Title         40108 non-null object\n",
      "IMDB Score    40060 non-null float64\n",
      "Genre         39963 non-null object\n",
      "Poster        39383 non-null object\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                            ]      0 / 930127\r",
      "  0% [                                                                            ]   8192 / 930127\r",
      "  1% [.                                                                           ]  16384 / 930127\r",
      "  2% [..                                                                          ]  24576 / 930127\r",
      "  3% [..                                                                          ]  32768 / 930127\r",
      "  4% [...                                                                         ]  40960 / 930127\r",
      "  5% [....                                                                        ]  49152 / 930127\r",
      "  6% [....                                                                        ]  57344 / 930127\r",
      "  7% [.....                                                                       ]  65536 / 930127\r",
      "  7% [......                                                                      ]  73728 / 930127\r",
      "  8% [......                                                                      ]  81920 / 930127\r",
      "  9% [.......                                                                     ]  90112 / 930127\r",
      " 10% [........                                                                    ]  98304 / 930127\r",
      " 11% [........                                                                    ] 106496 / 930127\r",
      " 12% [.........                                                                   ] 114688 / 930127\r",
      " 13% [..........                                                                  ] 122880 / 930127\r",
      " 14% [..........                                                                  ] 131072 / 930127\r",
      " 14% [...........                                                                 ] 139264 / 930127\r",
      " 15% [............                                                                ] 147456 / 930127\r",
      " 16% [............                                                                ] 155648 / 930127\r",
      " 17% [.............                                                               ] 163840 / 930127\r",
      " 18% [..............                                                              ] 172032 / 930127\r",
      " 19% [..............                                                              ] 180224 / 930127\r",
      " 20% [...............                                                             ] 188416 / 930127\r",
      " 21% [................                                                            ] 196608 / 930127\r",
      " 22% [................                                                            ] 204800 / 930127\r",
      " 22% [.................                                                           ] 212992 / 930127\r",
      " 23% [..................                                                          ] 221184 / 930127\r",
      " 24% [..................                                                          ] 229376 / 930127\r",
      " 25% [...................                                                         ] 237568 / 930127\r",
      " 26% [....................                                                        ] 245760 / 930127\r",
      " 27% [....................                                                        ] 253952 / 930127\r",
      " 28% [.....................                                                       ] 262144 / 930127\r",
      " 29% [......................                                                      ] 270336 / 930127\r",
      " 29% [......................                                                      ] 278528 / 930127\r",
      " 30% [.......................                                                     ] 286720 / 930127\r",
      " 31% [........................                                                    ] 294912 / 930127\r",
      " 32% [........................                                                    ] 303104 / 930127\r",
      " 33% [.........................                                                   ] 311296 / 930127\r",
      " 34% [..........................                                                  ] 319488 / 930127\r",
      " 35% [..........................                                                  ] 327680 / 930127\r",
      " 36% [...........................                                                 ] 335872 / 930127\r",
      " 36% [............................                                                ] 344064 / 930127\r",
      " 37% [............................                                                ] 352256 / 930127\r",
      " 38% [.............................                                               ] 360448 / 930127\r",
      " 39% [..............................                                              ] 368640 / 930127\r",
      " 40% [..............................                                              ] 376832 / 930127\r",
      " 41% [...............................                                             ] 385024 / 930127\r",
      " 42% [................................                                            ] 393216 / 930127\r",
      " 43% [................................                                            ] 401408 / 930127\r",
      " 44% [.................................                                           ] 409600 / 930127\r",
      " 44% [..................................                                          ] 417792 / 930127\r",
      " 45% [..................................                                          ] 425984 / 930127\r",
      " 46% [...................................                                         ] 434176 / 930127\r",
      " 47% [....................................                                        ] 442368 / 930127\r",
      " 48% [....................................                                        ] 450560 / 930127\r",
      " 49% [.....................................                                       ] 458752 / 930127\r",
      " 50% [......................................                                      ] 466944 / 930127\r",
      " 51% [......................................                                      ] 475136 / 930127\r",
      " 51% [.......................................                                     ] 483328 / 930127\r",
      " 52% [........................................                                    ] 491520 / 930127\r",
      " 53% [........................................                                    ] 499712 / 930127\r",
      " 54% [.........................................                                   ] 507904 / 930127\r",
      " 55% [..........................................                                  ] 516096 / 930127\r",
      " 56% [..........................................                                  ] 524288 / 930127\r",
      " 57% [...........................................                                 ] 532480 / 930127\r",
      " 58% [............................................                                ] 540672 / 930127\r",
      " 59% [............................................                                ] 548864 / 930127\r",
      " 59% [.............................................                               ] 557056 / 930127\r",
      " 60% [..............................................                              ] 565248 / 930127\r",
      " 61% [..............................................                              ] 573440 / 930127\r",
      " 62% [...............................................                             ] 581632 / 930127\r",
      " 63% [................................................                            ] 589824 / 930127\r",
      " 64% [................................................                            ] 598016 / 930127\r",
      " 65% [.................................................                           ] 606208 / 930127\r",
      " 66% [..................................................                          ] 614400 / 930127\r",
      " 66% [..................................................                          ] 622592 / 930127\r",
      " 67% [...................................................                         ] 630784 / 930127\r",
      " 68% [....................................................                        ] 638976 / 930127\r",
      " 69% [....................................................                        ] 647168 / 930127\r",
      " 70% [.....................................................                       ] 655360 / 930127\r",
      " 71% [......................................................                      ] 663552 / 930127\r",
      " 72% [......................................................                      ] 671744 / 930127\r",
      " 73% [.......................................................                     ] 679936 / 930127\r",
      " 73% [........................................................                    ] 688128 / 930127\r",
      " 74% [........................................................                    ] 696320 / 930127\r",
      " 75% [.........................................................                   ] 704512 / 930127\r",
      " 76% [..........................................................                  ] 712704 / 930127\r",
      " 77% [..........................................................                  ] 720896 / 930127\r",
      " 78% [...........................................................                 ] 729088 / 930127\r",
      " 79% [............................................................                ] 737280 / 930127\r",
      " 80% [............................................................                ] 745472 / 930127\r",
      " 81% [.............................................................               ] 753664 / 930127\r",
      " 81% [..............................................................              ] 761856 / 930127\r",
      " 82% [..............................................................              ] 770048 / 930127\r",
      " 83% [...............................................................             ] 778240 / 930127\r",
      " 84% [................................................................            ] 786432 / 930127\r",
      " 85% [................................................................            ] 794624 / 930127\r",
      " 86% [.................................................................           ] 802816 / 930127\r",
      " 87% [..................................................................          ] 811008 / 930127\r",
      " 88% [..................................................................          ] 819200 / 930127\r",
      " 88% [...................................................................         ] 827392 / 930127\r",
      " 89% [....................................................................        ] 835584 / 930127\r",
      " 90% [....................................................................        ] 843776 / 930127\r",
      " 91% [.....................................................................       ] 851968 / 930127\r",
      " 92% [......................................................................      ] 860160 / 930127\r",
      " 93% [......................................................................      ] 868352 / 930127\r",
      " 94% [.......................................................................     ] 876544 / 930127\r",
      " 95% [........................................................................    ] 884736 / 930127\r",
      " 96% [........................................................................    ] 892928 / 930127\r",
      " 96% [.........................................................................   ] 901120 / 930127\r",
      " 97% [..........................................................................  ] 909312 / 930127\r",
      " 98% [..........................................................................  ] 917504 / 930127\r",
      " 99% [........................................................................... ] 925696 / 930127\r",
      "100% [............................................................................] 930127 / 930127"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# initialize other parameters:\n",
    "INPUT_SHAPE = (224, 224)\n",
    "\n",
    "url_classes = 'https://raw.githubusercontent.com/nightrome/cocostuff/master/labels.txt'\n",
    "coco_classes = [str(x)[str(x).find(' '):].strip().replace(\"'\", '')\n",
    "                for x in urlopen(url_classes).read().splitlines()]\n",
    "hub_model = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\") # load the model only once!\n",
    "\n",
    "# face classification\n",
    "model_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "face_model = wget.download(model_url)\n",
    "\n",
    "face_classification = cv2.CascadeClassifier(face_model) # load the classifier only once!\n",
    "\n",
    "def apply_offsets(face_coordinates, offsets):\n",
    "    \"\"\"\n",
    "    Derived from https://github.com/oarriaga/face_classification/blob/\n",
    "    b861d21b0e76ca5514cdeb5b56a689b7318584f4/src/utils/inference.py#L21\n",
    "    \"\"\"\n",
    "    x, y, width, height = face_coordinates\n",
    "    x_off, y_off = offsets\n",
    "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
    "\n",
    "gender_classifier = load_model('gender_mini_XCEPTION.21-0.95.hdf5') # load this only once! (not in a loop)\n",
    "GENDER_OFFSETS = (10, 10)\n",
    "INPUT_SHAPE_GENDER = gender_classifier.input_shape[1:3]\n",
    "\n",
    "# emotion classification\n",
    "emotion_classifier = load_model('fer2013_mini_XCEPTION.102-0.66.hdf5') # load this only once! (not in a loop)\n",
    "\n",
    "EMOTION_OFFSETS = (0, 0)\n",
    "INPUT_SHAPE_EMOTION = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "emo_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "# Definition for color names\n",
    "def get_colour_name(rgb_triplet):\n",
    "    \"\"\"\n",
    "    From https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green-with-python\n",
    "    \"\"\"\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.CSS21_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb_triplet[0]) ** 2\n",
    "        gd = (g_c - rgb_triplet[1]) ** 2\n",
    "        bd = (b_c - rgb_triplet[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103239.jpg\n",
      "119239.jpg\n",
      "1381404.jpg\n",
      "1567437.jpg\n",
      "1975269.jpg\n",
      "3266948.jpg\n",
      "379889.jpg\n",
      "42383.jpg\n",
      "43587.jpg\n",
      "65494.jpg\n"
     ]
    }
   ],
   "source": [
    "results = [] # initialize the results dataframe\n",
    "\n",
    "for i in onlyfiles:\n",
    "    try: # some files don't seem to work, so I added this, to let the for loop just run further while a error occurs\n",
    "        # get the info from imdb, it will be stored at the end of the loop (title, genre and rating)\n",
    "        imdbID = int(i.split('.')[0])\n",
    "        imdb_info = imdb.loc[imdb['imdbId'] == imdbID]\n",
    "\n",
    "        # Get the amount of faces\n",
    "        pre_image = load_image_from_path(''.join(('movie_posters/',i)), target_size=(INPUT_SHAPE), color_mode='grayscale')\n",
    "        gray_image = np.squeeze(pre_image).astype('uint8')\n",
    "        faces = face_classification.detectMultiScale(gray_image, 1.3, 5) # detect the faces \n",
    "        n_faces = len(faces) # get the number of faces\n",
    "\n",
    "        # main gender of detected faces:\n",
    "        gender = 'unknown'\n",
    "\n",
    "        if n_faces > 0: \n",
    "            genders = np.zeros(shape=(n_faces,2)) # initialize\n",
    "            for j, face_coordinates in enumerate(faces): # using the output of the CascadeClassifier\n",
    "                x1, x2, y1, y2 = apply_offsets(face_coordinates, GENDER_OFFSETS) # extends the bounding box\n",
    "                face_img = gray_image[y1:y2, x1:x2] # only get the face \n",
    "                face_img = cv2.resize(face_img, (INPUT_SHAPE_GENDER)) # resize the image\n",
    "                face_img = face_img.astype('float32') / 255.0 # preprocess the image\n",
    "                face_img = np.expand_dims(face_img, 0) # batch of one\n",
    "                probas = gender_classifier.predict(face_img) \n",
    "                genders[j] = probas\n",
    "            if np.mean(genders[:,0])>np.mean(genders[:,1]):\n",
    "                gender = 'woman'\n",
    "            else:\n",
    "                gender = 'man'  \n",
    "\n",
    "        # main emotion of detected faces:\n",
    "        emotion = 'unknown'\n",
    "\n",
    "        if n_faces > 0:\n",
    "            emotions = np.zeros(shape=(n_faces,7))\n",
    "\n",
    "            for j, face_coordinates in enumerate(faces):\n",
    "                x1, x2, y1, y2 = apply_offsets(face_coordinates, EMOTION_OFFSETS) \n",
    "                face_img = gray_image[y1:y2, x1:x2] # only get the face\n",
    "                face_img = cv2.resize(face_img, (INPUT_SHAPE_EMOTION))\n",
    "                face_img = face_img.astype('float32') / 255.0 # pre-processing \n",
    "                face_img = face_img - 0.5 # pre-processing specific to the emotion classifier\n",
    "                face_img = face_img * 2.0 # pre-processing specific to the emotion classifier\n",
    "                face_img = np.expand_dims(face_img, 0) # batch of one\n",
    "                face_img = np.expand_dims(face_img, -1) # pre-processing specific to the emotion classifier\n",
    "                probas = emotion_classifier.predict(face_img)\n",
    "                emotions[j] = probas\n",
    "            highest = np.where(np.mean(emotions, axis=0) == np.amax(np.mean(emotions, axis=0)))\n",
    "            emotion = emo_labels[highest[0][0]]\n",
    "\n",
    "        # Number of persons (what was in the manual)\n",
    "        color_image = load_image_from_path(''.join(('movie_posters/',i)), target_size=(INPUT_SHAPE), color_mode='rgb').astype('uint8')\n",
    "        color_image_batched = np.expand_dims(color_image, axis=0) # batch size of one\n",
    "        R = hub_model(color_image_batched) # input the image to the modell\n",
    "\n",
    "        detection_scores = R['detection_scores'].numpy()[0]\n",
    "        detection_clases = R['detection_classes'].numpy()[0]\n",
    "        detection_bounding_box = R['detection_boxes'].numpy()[0]\n",
    "\n",
    "        indices = np.where(detection_scores > 0.5) # only select labels with p > 0.50 \n",
    "        detection_classes_sel = detection_clases[indices] # get the classes where p > 0.5\n",
    "        detection_scores_sel = detection_scores[indices] # get the probabilities where p > 0.5\n",
    "        detection_bb_sel = detection_bounding_box[indices] # get the bounding boxes where p > 0.5\n",
    "\n",
    "        # number of detectable objects\n",
    "        n_obj = len(detection_classes_sel)\n",
    "\n",
    "        # number of detectable persons\n",
    "        n_person = 0\n",
    "        for j, label in enumerate(detection_classes_sel):\n",
    "            textual_label = coco_classes[int(label)]\n",
    "            if textual_label == 'person':\n",
    "                n_person=+1\n",
    "\n",
    "        # Colors\n",
    "        color_image = load_image_from_path(''.join(('movie_posters/',i)), target_size=None, color_mode='rgb')\n",
    "        img = Image.fromarray(color_image.astype(np.uint8)) # convert to PIL image object\n",
    "        colors = colorgram.extract(img, 10) \n",
    "\n",
    "        main_color = get_colour_name(tuple(colors[0].rgb))\n",
    "        second_color = get_colour_name(tuple(colors[1].rgb))\n",
    "\n",
    "        median_r, median_g, median_b = np.median(color_image, axis=(0,1))\n",
    "\n",
    "        color_image_hsv = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV)\n",
    "        median_h, median_s, median_v = np.median(color_image_hsv, axis=(0,1))\n",
    "\n",
    "        # put all results in a dictionary and add that to the final results\n",
    "        res = {'Path': i,'Title': imdb_info['Title'].values[0],'Genre': imdb_info['Genre'].values[0],\n",
    "               'IMDB Rating':imdb_info['IMDB Score'].values[0],\n",
    "               '# faces': n_faces,'# persons':n_person, '# objects':n_obj,\n",
    "               'avgGender': gender, 'avgEmotion': emotion,\n",
    "               'mainColor': main_color, '2ndColor': second_color, 'medianR': median_r, 'medianG': median_g,\n",
    "               'medianB': median_b, 'medianH': median_h, 'medianS': median_s, 'medianV': median_v}\n",
    "        results.append(res)\n",
    "    except: \n",
    "        print(i) # print the images for which the algorithm doesn't work and are excluded form the results.\n",
    "        \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models I tried were had quite a bad performance, as the maximum R was 0.06. Maybe I should try making a mixed model (as we did for the epidemology course). But I think that is out of the scope of this excercise. Also, the models of this notebook aren't that good at predicting the amount of persons and faces etc. on movie posters. Better data and algorithms can improve the model. \n",
    "\n",
    "The best inidividual predictive feature seems to be the second color and after that the main color of the poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
