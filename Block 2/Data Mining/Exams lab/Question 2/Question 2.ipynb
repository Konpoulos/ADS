{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to my experience i think that the two best genres to compare the gender bias are: Metal and Hip-hop.Firstly i saw that both had almost the same number as samples,hip-hop is for me gender biased, rather than Metal. Because metal is more general and equaly distributed as songs though men and women.\n",
    "So my hypohtesis would be that hip-hop is more gender biased rather than metal which i think is equaly biased through both genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle \n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "import spacy\n",
    "import  pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora, models, similarities, downloader\n",
    "from tqdm import tqdm_notebook\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DF = 'english_cleaned_lyrics.csv'\n",
    "PATH_CORRECTION = 'indx2newdate.p'\n",
    "\n",
    "def load_dataset(data_path, path_correction):\n",
    "    df = pd.read_csv(data_path)\n",
    "    indx2newdate = pickle.load(open(PATH_CORRECTION, 'rb'))\n",
    "    df['year'] = df['index'].apply(lambda x: int(indx2newdate[x][0][:4]) if indx2newdate[x][0] != '' else 0)\n",
    "    return df[df.year > 1960][['song', 'year', 'artist', 'genre', 'lyrics']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load the dataset\n",
    "dataset = load_dataset(PATH_DF, PATH_CORRECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby how you doing You know I'm gonna cut r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all-i-could-do-was-cry</td>\n",
       "      <td>2008</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I heard Church bells ringing I heard A choir s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>once-in-a-lifetime</td>\n",
       "      <td>2008</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>This is just another day that I would spend Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>why-don-t-you-love-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>N n now honey You better sit down and look aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>poison</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You're bad for me I clearly get it I don't see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      song  year           artist genre  \\\n",
       "0                ego-remix  2009  beyonce-knowles   Pop   \n",
       "5   all-i-could-do-was-cry  2008  beyonce-knowles   Pop   \n",
       "6       once-in-a-lifetime  2008  beyonce-knowles   Pop   \n",
       "9    why-don-t-you-love-me  2009  beyonce-knowles   Pop   \n",
       "16                  poison  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                               lyrics  \n",
       "0   Oh baby how you doing You know I'm gonna cut r...  \n",
       "5   I heard Church bells ringing I heard A choir s...  \n",
       "6   This is just another day that I would spend Wa...  \n",
       "9   N n now honey You better sit down and look aro...  \n",
       "16  You're bad for me I clearly get it I don't see...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          77556\n",
       "Pop           23295\n",
       "Metal         15671\n",
       "Hip-Hop       14878\n",
       "Country       10545\n",
       "Electronic     5194\n",
       "Jazz           5068\n",
       "Indie          2489\n",
       "Other          2449\n",
       "R&B            2338\n",
       "Folk           1373\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will choose Metal and Hip-Hop as the 2 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picking the 2 geners\n",
    "df_metal = dataset[dataset.genre == 'Metal']\n",
    "df_Hip_Hop = dataset[dataset.genre == 'Hip-Hop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if i wanted that in online but takes too long to processs\n",
    "\n",
    "#data_metal_excl_punc_stop_words = df_metal['lyrics'].progress_apply(lambda x: [y.lemma_ for y in nlp(x) if not y.is_punct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_metal_excl_punc_stop_words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675a764e039c45efa4d8bb9b60396626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#first we have to tokenize both of the texts \n",
    "\n",
    "processed_texts = [text for text in tqdm_notebook(nlp.pipe(df_metal['lyrics'], \n",
    "                                              n_process=-1, # maximum number of threads\n",
    "                                              disable=[\"ner\",\n",
    "                                                       \"parser\"]),\n",
    "                                         total=len(df_metal['lyrics']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we take the tokenized text\n",
    "tokenized_df_metal = [[word.text for word in text if not word.is_punct] \n",
    "                    for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11566667, 14661110)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on metal songs\n",
    "SIZE = 100 # dimensions of the embeddings\n",
    "SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "WINDOW = 10 # the window size\n",
    "N_WORKERS = 1 # number of workers to use\n",
    "MIN_COUNT = 1\n",
    "\n",
    "model = Word2Vec(size=SIZE,\n",
    "                sg=SG,\n",
    "                window=WINDOW, \n",
    "                min_count=MIN_COUNT,\n",
    "                workers=N_WORKERS)\n",
    "\n",
    "model.build_vocab(tokenized_df_metal)\n",
    "\n",
    "model.train(tokenized_df_metal,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=model.epochs) # grab some coffee while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the 2 gender category words and the word_cats which has the catecories that we are going to use\n",
    "male_words = pd.read_pickle(\"male_words.p\")\n",
    "female_words = pd.read_pickle(\"female_words.p\")\n",
    "df =pd.read_pickle(\"word_cats.p\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_metal_words = [word for word in male_words if word in model.wv.vocab]\n",
    "female_metal_words = [word for word in female_words if word in model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_metal_mean = np.mean([model.wv[word] for word in male_metal_words], axis=0)\n",
    "female_metal_mean = np.mean([model.wv[word] for word in female_metal_words], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "#most of the code is from stack i just put those together in one piece\n",
    "categories = df.columns\n",
    "avg_bias = []\n",
    "\n",
    "for c in categories:# we iterate into the catecories one by one\n",
    "    left = df[c].isna().sum() #check whats left of the Dataframe \n",
    "    words = []\n",
    "    bias_list = []\n",
    "    for i in range(n-left):\n",
    "        s = df[c].loc[i] #get the word from the dataframe\n",
    "        if s in model.wv.vocab: \n",
    "            embeding = model.wv[s] #calculate embedding for the word\n",
    "            male_dist = np.linalg.norm(np.subtract(male_metal_mean, embeding)) #calculate distances\n",
    "            female_dist = np.linalg.norm(np.subtract(female_metal_mean, embeding))       \n",
    "            words.append(s)\n",
    "            bias_list.append(male_dist - female_dist)#thats the bias per list\n",
    "    avg_bias.append(np.sum(bias_list)/(n-left)) #calculate average bias and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create the dataframe merging the categories together\n",
    "per_metal_category = pd.DataFrame(zip(categories,avg_bias))\n",
    "#we now have to name the columns\n",
    "per_metal_category.columns = ['category','average_bias']\n",
    "#we sort the values\n",
    "per_metal_category.sort_values('average_bias', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percept</td>\n",
       "      <td>0.018632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relig</td>\n",
       "      <td>0.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>posemo</td>\n",
       "      <td>-0.005627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negemo</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affect</td>\n",
       "      <td>-0.006179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>-0.009857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>body</td>\n",
       "      <td>-0.022307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social</td>\n",
       "      <td>-0.026634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>-0.035701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>leisure</td>\n",
       "      <td>-0.043171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occupation</td>\n",
       "      <td>-0.051911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.061761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.072385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  average_bias\n",
       "6      percept      0.018632\n",
       "11       relig      0.006568\n",
       "1       posemo     -0.005627\n",
       "2       negemo     -0.005741\n",
       "0       affect     -0.006179\n",
       "5      cogproc     -0.009857\n",
       "7         body     -0.022307\n",
       "3       social     -0.026634\n",
       "4       family     -0.035701\n",
       "9      leisure     -0.043171\n",
       "12  occupation     -0.051911\n",
       "8         work     -0.061761\n",
       "10       money     -0.072385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_metal_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70e98c550f8491aa8ab7e1dbb0e3b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14878.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_texts2 = [text for text in tqdm_notebook(nlp.pipe(df_Hip_Hop['lyrics'], \n",
    "                                              n_process=-1, # maximum number of threads\n",
    "                                              disable=[\"ner\",\n",
    "                                                       \"parser\"]),\n",
    "                                         total=len(df_Hip_Hop['lyrics']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_df_Hip_Hop = [[word.text for word in text if not word.is_punct] \n",
    "                    for text in processed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11566667, 14661110)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on hip hop songs,actualy here i may could use size=300 or min_count = 5 but i dont think i should have different answers\n",
    "SIZE = 100 # dimensions of the embeddings\n",
    "SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "WINDOW = 10 # the window size\n",
    "N_WORKERS = 1 # number of workers to use\n",
    "MIN_COUNT = 1\n",
    "\n",
    "model = Word2Vec(size=SIZE,\n",
    "                sg=SG,\n",
    "                window=WINDOW, \n",
    "                min_count=MIN_COUNT,\n",
    "                workers=N_WORKERS)\n",
    "\n",
    "model.build_vocab(tokenized_df_Hip_Hop)\n",
    "\n",
    "model.train(tokenized_df_Hip_Hop,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=model.epochs) # grab some coffee while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_hip_hop_words = [word for word in male_words if word in model.wv.vocab]\n",
    "female_hip_hop_words = [word for word in female_words if word in model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_hip_hop_mean = np.mean([model.wv[word] for word in male_hip_hop_words], axis=0)\n",
    "female_hip_hop_mean = np.mean([model.wv[word] for word in female_hip_hop_words], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "#most of the code is from stack i just put those together in one piece\n",
    "categories = df.columns\n",
    "avg_bias = []\n",
    "\n",
    "for c in categories:# we iterate into the catecories one by one\n",
    "    left = df[c].isna().sum() #check whats left of the Dataframe \n",
    "    words = []\n",
    "    bias_list = []\n",
    "    for i in range(n-left):\n",
    "        s = df[c].loc[i] #get the word from the dataframe\n",
    "        if s in model.wv.vocab: \n",
    "            embeding = model.wv[s] #calculate embedding for the word\n",
    "            male_dist = np.linalg.norm(np.subtract(male_hip_hop_mean, embeding)) #calculate distances from the manual\n",
    "            female_dist = np.linalg.norm(np.subtract(female_hip_hop_mean, embeding))       \n",
    "            words.append(s)\n",
    "            bias_list.append(male_dist - female_dist)#thats the bias per list\n",
    "    avg_bias.append(np.sum(bias_list)/(n-left)) #calculate average bias and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create the dataframe merging the categories together\n",
    "per_hip_hop_category = pd.DataFrame(zip(categories,avg_bias))\n",
    "#we now have to name the columns\n",
    "per_hip_hop_category.columns = ['category','average_bias']\n",
    "#we sort the values\n",
    "per_hip_hop_category.sort_values('average_bias', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percept</td>\n",
       "      <td>0.021491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relig</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>posemo</td>\n",
       "      <td>-0.009245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>-0.011145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negemo</td>\n",
       "      <td>-0.011314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>body</td>\n",
       "      <td>-0.012688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>-0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affect</td>\n",
       "      <td>-0.022802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>leisure</td>\n",
       "      <td>-0.033806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.043278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occupation</td>\n",
       "      <td>-0.051911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social</td>\n",
       "      <td>-0.053267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.072545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  average_bias\n",
       "6      percept      0.021491\n",
       "11       relig      0.003024\n",
       "1       posemo     -0.009245\n",
       "4       family     -0.011145\n",
       "2       negemo     -0.011314\n",
       "7         body     -0.012688\n",
       "5      cogproc     -0.020784\n",
       "0       affect     -0.022802\n",
       "9      leisure     -0.033806\n",
       "10       money     -0.043278\n",
       "12  occupation     -0.051911\n",
       "3       social     -0.053267\n",
       "8         work     -0.072545"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_hip_hop_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percept</td>\n",
       "      <td>0.018632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relig</td>\n",
       "      <td>0.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>posemo</td>\n",
       "      <td>-0.005627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negemo</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affect</td>\n",
       "      <td>-0.006179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>-0.009857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>body</td>\n",
       "      <td>-0.022307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social</td>\n",
       "      <td>-0.026634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>-0.035701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>leisure</td>\n",
       "      <td>-0.043171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occupation</td>\n",
       "      <td>-0.051911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.061761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.072385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  average_bias\n",
       "6      percept      0.018632\n",
       "11       relig      0.006568\n",
       "1       posemo     -0.005627\n",
       "2       negemo     -0.005741\n",
       "0       affect     -0.006179\n",
       "5      cogproc     -0.009857\n",
       "7         body     -0.022307\n",
       "3       social     -0.026634\n",
       "4       family     -0.035701\n",
       "9      leisure     -0.043171\n",
       "12  occupation     -0.051911\n",
       "8         work     -0.061761\n",
       "10       money     -0.072385"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_metal_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After i saw the results of the code it is clear that almost both genres are equaly biased.In both gendes the most 3 biased categories are percept,relig and posemo which are Perceptual Processes and every person has different meanings for perception , also religion a very contrast believing in any situation and last Positive emotions they arise from listening to music.\n",
    "Work is most biased through men in hip-hop and money is most biased in metal for men.\n",
    "\n",
    "So my hypothesis was not correct because i thought that hip-hop will be more biased rather than metal,after making the analysis it is clear that both my genres are equaly biased and almost in the same categories.After the analysis i think that the results are logical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
