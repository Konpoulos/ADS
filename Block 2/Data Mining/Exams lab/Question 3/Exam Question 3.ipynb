{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCPI95REuhie"
   },
   "source": [
    "I am trying to convince a person who has no clue about data science which is the best way to release his movie,my conclusion has to be easily understandable by him,thats the difficult part in data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nHq_SQxzrjzz"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle \n",
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import spacy\n",
    "import  pickle\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm_notebook\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBCm5ruDuKZ2"
   },
   "source": [
    "I presend my steps through this procedure,firstly i split the dataset into 2 subsets.Assuming is the best way to realise which is the best way to approach this problem.I beging preprocessing my data with spacy,split into tokens,remove stop words, lemmatize and remove special characters if i see fit.Second i try to create both bag of words(BOW) i use Word2Vec for that with size=300 to have a good embedding size and i only take words with above 5 appearences.Creating a list out of the dictionary with the most frequent and unique word for every subset.Now that i have the BOW for both linear and netflix we can create a list of words.I named it satisfied list, because at the end of day what matters most is to find which type will engage the audience more.Then i create a log-likelihood measure to compare the the frequency of BOWs between the list and the one with the biggest score will be the case for our analysis.Like if the BOW from netflix has better score to the satisfied list then my conclusion to the producer is to release his movie with the type of netflix otherwise with the type of linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1TKWOML0rq5k"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('discussions_corrected.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JlhMNq4zrwMR",
    "outputId": "c29ffbdf-5c41-41f1-fba8-8fd3c95dd752"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>Walter. And there the chain ends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>I love this show. But it's hard to argue again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>What am I missing?  A lot of reference to ribs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oh come on Mike, he's a good little boy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>Look again ðŸ‘€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title  ...                                               post\n",
       "0  Better Call Saul  ...                  Walter. And there the chain ends.\n",
       "1  Better Call Saul  ...  I love this show. But it's hard to argue again...\n",
       "2  Better Call Saul  ...  What am I missing?  A lot of reference to ribs...\n",
       "3  Better Call Saul  ...          Oh come on Mike, he's a good little boy. \n",
       "4  Better Call Saul  ...                                       Look again ðŸ‘€\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feiEy47sGnoQ",
    "outputId": "2b9148cc-520d-4fd8-f55f-eae635f751ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Game of Thrones            15462\n",
       "Breaking Bad                6424\n",
       "Better Call Saul            5268\n",
       "Black Mirror                4720\n",
       "Stranger Things             2891\n",
       "True Detective              2721\n",
       "Twin Peaks                  2399\n",
       "Dark                        2004\n",
       "Ozark                       1417\n",
       "Mr. Robot                   1347\n",
       "Orange is the New Black     1208\n",
       "The Witcher                 1188\n",
       "Fargo                        680\n",
       "Mindhunter                   657\n",
       "The Newsroom                 484\n",
       "Succession                   389\n",
       "The Crown                    338\n",
       "House of Cards               158\n",
       "La Casa de Papel             150\n",
       "The Mandelorian               95\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Wws9OwGtseqp"
   },
   "outputs": [],
   "source": [
    "#spliting the dataset into 2 subsets through type\n",
    "df_linear = df[df.type == 'linear']\n",
    "df_netflix = df[df.type == 'netflix']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UGUINthJshAp"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "4e9e00a8f4234fbea6b8130bd69721b1",
      "2cb34a0b94104be78cb9bfae485fc02a",
      "c0430fbfedda4e78aab74141f2ef3237",
      "be9fe2cf5fba42c09dc166cd7919226a",
      "f2b2539935a947f9adac5a1b023045b3",
      "f622ab5383624e51ba49b79c41d7a82b",
      "654ece7e59724ed2bfdd28594e384aef",
      "5d426ae725db4177b88fb3992ea40c4f"
     ]
    },
    "id": "Rvz6lgMVtOXp",
    "outputId": "ce13cf52-2ae6-4bc4-96ae-ec8cdf4f3f9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e00a8f4234fbea6b8130bd69721b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35269.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use the pipe to preprocess the data and tokenize them\n",
    "processed_texts = [text for text in tqdm_notebook(nlp.pipe(df_linear['post'], \n",
    "                                              n_process=-1, # maximum number of threads\n",
    "                                              disable=[\"ner\",\n",
    "                                                       \"parser\"]),\n",
    "                                         total=len(df_linear['post']))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "R1iYdXNZIvT7"
   },
   "outputs": [],
   "source": [
    "tokenized_df_linear = [[token.lemma_ for token in text\n",
    "               if not token.is_punct and not token.is_stop]\n",
    "              for text in processed_texts]                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cm2U-8asIZLD",
    "outputId": "aa165727-aa82-45a8-f904-9e60f306023e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Walter', 'chain', 'end']]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tokenized_df_linear = [[re.sub(r'\\W+', '', word) for word in text] for text in tokenized_df_linear] #we remove the words we dont want\n",
    " tokenized_df_linear[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJnW4aLwU4y5",
    "outputId": "4eb12336-ead4-4980-95ce-2101ddc762fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Walter', 'chain', '']]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tokenized_df_linear2 = [[re.sub(r'\\b\\w{1,3}\\b', '', word) for word in text] for text in tokenized_df_linear] # we remove the words that are 3 or more,in my opinion they are noise\n",
    " tokenized_df_linear2[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "6dbb8ff5d3cf42f39de541bf1d60c807",
      "dd21c765d69d4041aa4cb7da4941ba6c",
      "4f204af62b1e4647b482027f894b4306",
      "e8027f08605a40c2827fd77d81cf0ebb",
      "eb774d037a5744559e3ae15960e06e31",
      "294c20f6e83b424482c98f6639795b1e",
      "396d196fd68f49f186893521dd5f4bdf",
      "b445a811e62c4809be34f077f744b0b2"
     ]
    },
    "id": "AoRhFfjNuHui",
    "outputId": "de10c788-b75c-4084-abaf-2af5c3365eb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbb8ff5d3cf42f39de541bf1d60c807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14731.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_texts = [text for text in tqdm_notebook(nlp.pipe(df_netflix['post'], \n",
    "                                              n_process=-1, # maximum number of threads\n",
    "                                              disable=[\"ner\",\n",
    "                                                       \"parser\"]),\n",
    "                                         total=len(df_netflix['post']))]\n",
    "\n",
    "\n",
    "tokenized_df_netflix = [[token.lemma_ for token in text\n",
    "               if not token.is_punct and not token.is_stop]\n",
    "              for text in processed_texts]                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpwW2dL4OunD",
    "outputId": "37cc7678-b079-4fca-ab3f-8b1695cafd70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['think', 'rabbit', 'end', 'real', 'ending', 'traincrasch']]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df_netflix = [[re.sub(r'\\W+', '', word) for word in text] for text in tokenized_df_netflix] #remove the \\n\n",
    "tokenized_df_netflix[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWe0jWL7V82R",
    "outputId": "cdf21a52-c0f6-458b-b3a8-00922d14cb02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['think', 'rabbit', '', 'real', 'ending', 'traincrasch'],\n",
       " ['wipe', '', 'tracker', 'realize', 'fate']]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df_netflix2 = [[re.sub(r'\\b\\w{1,3}\\b', '', word) for word in text] for text in tokenized_df_netflix] #remove the numbers\n",
    "tokenized_df_netflix2[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yn0DCMWujUXz",
    "outputId": "c023baac-aa4f-426f-9f73-32a3a8e0b8c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Walter', 'chain', 'end']]"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df_linear[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-dpeOuWjWhK",
    "outputId": "8d5f2cc4-1fc3-408f-bd86-4c00949cdff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['think', 'rabbit', 'end', 'real', 'ending', 'traincrasch'],\n",
       " ['wipe', 'eat', 'tracker', 'realize', 'fate']]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df_netflix[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXOj2CcIq-9R",
    "outputId": "a807c5e4-0cb8-4182-dac0-242d02d6b728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675332, 997445)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i use W2v to create the WOB \n",
    "SIZE = 300 # dimensions of the embeddings\n",
    "SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "WINDOW = 10 # the window size\n",
    "N_WORKERS = 1 # number of workers to use\n",
    "MIN_COUNT = 5\n",
    "\n",
    "model = Word2Vec(size=SIZE,\n",
    "                sg=SG,\n",
    "                window=WINDOW, \n",
    "                min_count=MIN_COUNT,\n",
    "                workers=N_WORKERS)\n",
    "\n",
    "model.build_vocab(tokenized_df_netflix2)\n",
    "\n",
    "model.train(tokenized_df_netflix2,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HQV4Vb3KAeC",
    "outputId": "3e0ea70d-4608-43db-b187-94100f71bb2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3897"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "vm763pOxZHkk"
   },
   "outputs": [],
   "source": [
    "# i create the first wob from the netflix and they are all unique words \n",
    "BOW1 = []\n",
    "for key, value in model.wv.vocab.items(): \n",
    "  BOW1.append(key)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9vtlP4EawJZ",
    "outputId": "14f53a6a-f33b-462a-b315-b9501b19a71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think', 'rabbit']"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOB1[:2] #now the datas are clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTGjrF_oeD3S",
    "outputId": "9a363c4e-3651-4780-cb28-c86fe25c2a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1220047, 1771970)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = 300 # dimensions of the embeddings\n",
    "SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "WINDOW = 10 # the window size\n",
    "N_WORKERS = 1 # number of workers to use\n",
    "MIN_COUNT = 5\n",
    "\n",
    "model = Word2Vec(size=SIZE,\n",
    "                sg=SG,\n",
    "                window=WINDOW, \n",
    "                min_count=MIN_COUNT,\n",
    "                workers=N_WORKERS)\n",
    "\n",
    "model.build_vocab(tokenized_df_linear2)\n",
    "\n",
    "model.train(tokenized_df_linear2,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7pGusaLRfm9J"
   },
   "outputs": [],
   "source": [
    "# i create the first wob from the linear and they are all unique words \n",
    "BOW2 = []\n",
    "for key, value in model.wv.vocab.items(): \n",
    "  BOW2.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAm8VLrag4DS",
    "outputId": "51eedf0a-8023-44e8-91e0-e256b7ad8c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walter', 'chain']"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTzFM9uwqop4"
   },
   "source": [
    "Now that i have the BOW for both linear and netflix i can create a new list of words,which will contain words that declare good ratio.I named it satisfied list.Then i create a log-likelihood measure to compare the the frequency of BOWs between the list and the one with the biggest score will be the case for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "LLM1Zeoqig5J"
   },
   "outputs": [],
   "source": [
    "sarisfied_list = ['good','nice','gratified','happy','joyful','joyous']#i could go on but i think the idea is the point here not the actual result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "WVvq1OfUiMIc"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "flatten = lambda t: [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "0mKPtmX7iNlP"
   },
   "outputs": [],
   "source": [
    "# i will not forget to flatten\n",
    "flatten_WOB1 = flatten(BOW1)\n",
    "flatten_WOB2 = flatten(BOW2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "7Mxi21UgO7s1"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "tokenized_text_corpus_1 = BOW1\n",
    "tokenized_text_corpus_2 = sarisfied_list\n",
    "\n",
    "counts_c1 = Counter(tokenized_text_corpus_1)\n",
    "counts_c2 = Counter(tokenized_text_corpus_2)\n",
    "\n",
    "freq_c1_other = sum(counts_c1.values()) \n",
    "freq_c2_other = sum(counts_c2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Q2pki8qTAgj",
    "outputId": "8d61ce73-371c-4309-d67a-1b7a73eaf906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood:  4.116294033801272\n",
      "p-value:  0.04247202129760274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "llr, p_value,_,_ = chi2_contingency([[freq_c1, freq_c2], \n",
    "                  [freq_c1_other, freq_c2_other]],\n",
    "                  lambda_='log-likelihood') # this specifies using the LL measure\n",
    "print(\"Log-likelihood: \", llr)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "ud-RHtcQfIZb"
   },
   "outputs": [],
   "source": [
    "tokenized_text_corpus_1 = BOW2\n",
    "tokenized_text_corpus_2 = sarisfied_list\n",
    "\n",
    "counts_c1 = Counter(tokenized_text_corpus_1)\n",
    "counts_c2 = Counter(tokenized_text_corpus_2)\n",
    "\n",
    "freq_c1_other = sum(counts_c1.values()) \n",
    "freq_c2_other = sum(counts_c2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wx7P-RbfgwRi",
    "outputId": "0c988a72-dd27-42b2-f562-cd9f99dc8c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood:  4.505111852689309\n",
      "p-value:  0.03379368592884378\n"
     ]
    }
   ],
   "source": [
    "llr, p_value,_,_ = chi2_contingency([[freq_c1, freq_c2], \n",
    "                  [freq_c1_other, freq_c2_other]],\n",
    "                  lambda_='log-likelihood') # this specifies using the LL measure\n",
    "print(\"Log-likelihood: \", llr)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5OflpK2k4Wa"
   },
   "source": [
    "From the results its more likely to have the satisfied words in BOW2 but before precenting my answer i should have done normalization.One subset was way smaller than the other,but due to restricted time i was not able to present that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOZ6wUfeft5e"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4D5bqR0f_w9"
   },
   "source": [
    "Different from i have done so far,my analaysis was in a real case scenario,i used the dataset to create my insites and finish the assigment with a solid result.My answer to the producer:\"Data are the most important fuel in order to build a proper analysis,my method proves the linear model to be more effective than the netflix one.So i strongly recomend you follow the result and release it Linear!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C9ByKlRkTAL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "294c20f6e83b424482c98f6639795b1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cb34a0b94104be78cb9bfae485fc02a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "396d196fd68f49f186893521dd5f4bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e9e00a8f4234fbea6b8130bd69721b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0430fbfedda4e78aab74141f2ef3237",
       "IPY_MODEL_be9fe2cf5fba42c09dc166cd7919226a"
      ],
      "layout": "IPY_MODEL_2cb34a0b94104be78cb9bfae485fc02a"
     }
    },
    "4f204af62b1e4647b482027f894b4306": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_294c20f6e83b424482c98f6639795b1e",
      "max": 14731,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb774d037a5744559e3ae15960e06e31",
      "value": 14731
     }
    },
    "5d426ae725db4177b88fb3992ea40c4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "654ece7e59724ed2bfdd28594e384aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dbb8ff5d3cf42f39de541bf1d60c807": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f204af62b1e4647b482027f894b4306",
       "IPY_MODEL_e8027f08605a40c2827fd77d81cf0ebb"
      ],
      "layout": "IPY_MODEL_dd21c765d69d4041aa4cb7da4941ba6c"
     }
    },
    "b445a811e62c4809be34f077f744b0b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be9fe2cf5fba42c09dc166cd7919226a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d426ae725db4177b88fb3992ea40c4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_654ece7e59724ed2bfdd28594e384aef",
      "value": " 35269/35269 [00:50&lt;00:00, 701.45it/s]"
     }
    },
    "c0430fbfedda4e78aab74141f2ef3237": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f622ab5383624e51ba49b79c41d7a82b",
      "max": 35269,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2b2539935a947f9adac5a1b023045b3",
      "value": 35269
     }
    },
    "dd21c765d69d4041aa4cb7da4941ba6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8027f08605a40c2827fd77d81cf0ebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b445a811e62c4809be34f077f744b0b2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_396d196fd68f49f186893521dd5f4bdf",
      "value": " 14731/14731 [00:25&lt;00:00, 582.18it/s]"
     }
    },
    "eb774d037a5744559e3ae15960e06e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f2b2539935a947f9adac5a1b023045b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f622ab5383624e51ba49b79c41d7a82b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
